####################################################### DOCKER #######################################################
COMPOSE_FILE=docker-compose.yml:docker-compose.local.yml
COMPOSE_PROJECT_NAME=llm

####################################################### PROJECT #######################################################
MODEL_ID=distilgpt2
DTYPE=float32
TORCH_THREADS=4

# MLflow
MLFLOW_HOST=mlflow
MLFLOW_PORT=5000
MLFLOW_EXPERIMENT=inference
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_S3_ENDPOINT_URL=http://minio:9000

# vLLM
VLLM_MODEL=Qwen/Qwen3-0.6B
VLLM_HOST=vllm
VLLM_PORT=8000

# OpenAI
OPENAI_BASE_URL=http://vllm:8000/v1
OPENAI_API_KEY=EMPTY

####################################################### SERVICES #######################################################
# Postgres
DB_HOST=pgsql
DB_PORT=5432
DB_DATABASE=app
DB_USERNAME=llm
DB_PASSWORD=p@ssw0rd

# MinIO / S3
AWS_ACCESS_KEY_ID=app
AWS_SECRET_ACCESS_KEY=p@ssw0rd
AWS_DEFAULT_REGION=local
AWS_BUCKET=app

# Grafana
GF_SECURITY_ADMIN_USER=app
GF_SECURITY_ADMIN_PASSWORD=p@ssw0rd
